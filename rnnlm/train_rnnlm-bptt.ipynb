{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_rnnlm-2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"V7RcFkFmHJqx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"e6c336d7-7941-48b3-f36c-22fa92b4b1b1","executionInfo":{"status":"ok","timestamp":1533954983966,"user_tz":-540,"elapsed":1939,"user":{"displayName":"HARADA Tomohiko","photoUrl":"//lh3.googleusercontent.com/-NhVNZogeGbU/AAAAAAAAAAI/AAAAAAAAAB4/SUNHPkvUldw/s50-c-k-no/photo.jpg","userId":"102955192351597992804"}}},"cell_type":"code","source":["!df -h"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Filesystem      Size  Used Avail Use% Mounted on\r\n","overlay         359G  6.3G  334G   2% /\r\n","tmpfs           6.4G     0  6.4G   0% /dev\r\n","tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\r\n","tmpfs           6.4G  249M  6.2G   4% /opt/bin\r\n","/dev/sda1       365G  8.1G  357G   3% /etc/hosts\r\n","shm              64M     0   64M   0% /dev/shm\r\n","tmpfs           6.4G     0  6.4G   0% /sys/firmware\r\n"],"name":"stdout"}]},{"metadata":{"id":"wBcsYE8hau2J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2e2574ab-2899-4cd5-d032-4253f2ff1124","executionInfo":{"status":"ok","timestamp":1534677885035,"user_tz":-540,"elapsed":2584,"user":{"displayName":"HARADA Tomohiko","photoUrl":"//lh3.googleusercontent.com/-NhVNZogeGbU/AAAAAAAAAAI/AAAAAAAAAB4/SUNHPkvUldw/s50-c-k-no/photo.jpg","userId":"102955192351597992804"}}},"cell_type":"code","source":["# 起動時間\n","!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["0.00335081days (289.51sec)\r\n"],"name":"stdout"}]},{"metadata":{"id":"pcsST61uGqpt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1006},"outputId":"07fd3540-867a-430b-b2d6-568130796bbf","executionInfo":{"status":"ok","timestamp":1534888849335,"user_tz":-540,"elapsed":32116,"user":{"displayName":"HARADA Tomohiko","photoUrl":"//lh3.googleusercontent.com/-NhVNZogeGbU/AAAAAAAAAAI/AAAAAAAAAB4/SUNHPkvUldw/s50-c-k-no/photo.jpg","userId":"102955192351597992804"}}},"cell_type":"code","source":["!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n","!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n","!pip install -U cupy_cuda80\n","!pip install -U chainer"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n","0 upgraded, 3 newly installed, 0 to remove and 0 not upgraded.\n","Need to get 28.9 MB of archives.\n","After this operation, 71.6 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu artful/multiverse amd64 libcusparse8.0 amd64 8.0.61-1 [22.6 MB]\n","Get:2 http://archive.ubuntu.com/ubuntu artful/multiverse amd64 libnvrtc8.0 amd64 8.0.61-1 [6,225 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu artful/multiverse amd64 libnvtoolsext1 amd64 8.0.61-1 [32.2 kB]\n","Fetched 28.9 MB in 0s (58.2 MB/s)\n","\n","\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libcusparse8.0:amd64.\n","(Reading database ... 18408 files and directories currently installed.)\n","Preparing to unpack .../libcusparse8.0_8.0.61-1_amd64.deb ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libcusparse8.0:amd64 (8.0.61-1) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [#######...................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libnvrtc8.0:amd64.\n","Preparing to unpack .../libnvrtc8.0_8.0.61-1_amd64.deb ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking libnvrtc8.0:amd64 (8.0.61-1) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package libnvtoolsext1:amd64.\n","Preparing to unpack .../libnvtoolsext1_8.0.61-1_amd64.deb ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking libnvtoolsext1:amd64 (8.0.61-1) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up libnvtoolsext1:amd64 (8.0.61-1) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libcusparse8.0:amd64 (8.0.61-1) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up libnvrtc8.0:amd64 (8.0.61-1) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [######################################################....] \u001b8Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n","\n","\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JCollecting cupy_cuda80\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/82/9eb531d941b22021ee47e7946a551beca407f532f5834ceb5efad6c1c20d/cupy_cuda80-4.3.0-cp36-cp36m-manylinux1_x86_64.whl (200.4MB)\n","\u001b[K    100% |████████████████████████████████| 200.4MB 150kB/s \n","\u001b[?25hCollecting fastrlock>=0.3 (from cupy_cuda80)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/24/767ce4fe23af5a4b3dd229c0e3153a26c0a58331f8f89af324c761663c9c/fastrlock-0.3-cp36-cp36m-manylinux1_x86_64.whl (77kB)\n","\u001b[K    100% |████████████████████████████████| 81kB 20.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy_cuda80) (1.11.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy_cuda80) (1.14.5)\n","Installing collected packages: fastrlock, cupy-cuda80\n","Successfully installed cupy-cuda80-4.3.0 fastrlock-0.3\n","Collecting chainer\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/c6/61ff9041ea7427fc1e39768f740ab8b880f8ef20960a5f791e978e8d81c0/chainer-4.3.1.tar.gz (400kB)\n","\u001b[K    100% |████████████████████████████████| 409kB 19.9MB/s \n","\u001b[?25hCollecting filelock (from chainer)\n","  Downloading https://files.pythonhosted.org/packages/2d/ba/db7e0717368958827fa97af0b8acafd983ac3a6ecd679f60f3ccd6e5b16e/filelock-3.0.4.tar.gz\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.14.5)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.1)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.11.0)\n","Requirement already satisfied, skipping upgrade: cupy-cuda80<5.0.0,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (4.3.0)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->chainer) (39.1.0)\n","Requirement already satisfied, skipping upgrade: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80<5.0.0,>=4.3.0->chainer) (0.3)\n","Building wheels for collected packages: chainer, filelock\n","  Running setup.py bdist_wheel for chainer ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/8a/ef/b0/e67e0555c4d520566d6565d9634ecb7fbb1594758236bb7b40\n","  Running setup.py bdist_wheel for filelock ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/35/ba/67/4cc48738870c3b54f9e3b5d78bf9de130befb70c1d359faf8b\n","Successfully built chainer filelock\n","Installing collected packages: filelock, chainer\n","Successfully installed chainer-4.3.1 filelock-3.0.4\n"],"name":"stdout"}]},{"metadata":{"id":"RsZae1iCGTZu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"96a3a205-2342-4b50-c7fe-967d47c0242d","executionInfo":{"status":"ok","timestamp":1534888868987,"user_tz":-540,"elapsed":5414,"user":{"displayName":"HARADA Tomohiko","photoUrl":"//lh3.googleusercontent.com/-NhVNZogeGbU/AAAAAAAAAAI/AAAAAAAAAB4/SUNHPkvUldw/s50-c-k-no/photo.jpg","userId":"102955192351597992804"}}},"cell_type":"code","source":["import chainer\n","print('GPU availability:', chainer.cuda.available)\n","print('cuDNN availablility:', chainer.cuda.cudnn_enabled)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["GPU availability: True\n","cuDNN availablility: True\n"],"name":"stdout"}]},{"metadata":{"id":"HjTK9-YEH3Lr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2278},"outputId":"46703ea8-d5e6-4a0d-fd41-9697c0e74cb2","executionInfo":{"status":"ok","timestamp":1534888896883,"user_tz":-540,"elapsed":26921,"user":{"displayName":"HARADA Tomohiko","photoUrl":"//lh3.googleusercontent.com/-NhVNZogeGbU/AAAAAAAAAAI/AAAAAAAAAB4/SUNHPkvUldw/s50-c-k-no/photo.jpg","userId":"102955192351597992804"}}},"cell_type":"code","source":["# google-drive-ocamlfuse のインストール\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Preconfiguring packages ...\n","Selecting previously unselected package cron.\n","(Reading database ... 18431 files and directories currently installed.)\n","Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n","Unpacking cron (3.0pl1-128ubuntu5) ...\n","Selecting previously unselected package libapparmor1:amd64.\n","Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n","Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n","Selecting previously unselected package libdbus-1-3:amd64.\n","Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n","Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n","Selecting previously unselected package dbus.\n","Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n","Unpacking dbus (1.10.22-1ubuntu1) ...\n","Selecting previously unselected package dirmngr.\n","Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n","Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n","Selecting previously unselected package distro-info-data.\n","Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n","Unpacking distro-info-data (0.36ubuntu0.2) ...\n","Selecting previously unselected package libkmod2:amd64.\n","Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n","Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n","Selecting previously unselected package kmod.\n","Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n","Unpacking kmod (24-1ubuntu2) ...\n","Selecting previously unselected package lsb-release.\n","Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n","Unpacking lsb-release (9.20160110ubuntu5) ...\n","Selecting previously unselected package libgirepository-1.0-1:amd64.\n","Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n","Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n","Selecting previously unselected package gir1.2-glib-2.0:amd64.\n","Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n","Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n","Selecting previously unselected package iso-codes.\n","Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n","Unpacking iso-codes (3.75-1) ...\n","Selecting previously unselected package libdbus-glib-1-2:amd64.\n","Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n","Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n","Selecting previously unselected package python-apt-common.\n","Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n","Unpacking python-apt-common (1.4.0~beta3build2) ...\n","Selecting previously unselected package python3-apt.\n","Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n","Unpacking python3-apt (1.4.0~beta3build2) ...\n","Selecting previously unselected package python3-dbus.\n","Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n","Unpacking python3-dbus (1.2.4-1build3) ...\n","Selecting previously unselected package python3-gi.\n","Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n","Unpacking python3-gi (3.24.1-2build1) ...\n","Selecting previously unselected package module-init-tools.\n","Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n","Unpacking module-init-tools (24-1ubuntu2) ...\n","Selecting previously unselected package python-apt.\n","Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n","Unpacking python-apt (1.4.0~beta3build2) ...\n","Selecting previously unselected package python-pycurl.\n","Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n","Unpacking python-pycurl (7.43.0-2build2) ...\n","Selecting previously unselected package python-software-properties.\n","Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n","Unpacking python-software-properties (0.96.24.17) ...\n","Selecting previously unselected package python3-software-properties.\n","Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n","Unpacking python3-software-properties (0.96.24.17) ...\n","Selecting previously unselected package software-properties-common.\n","Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n","Unpacking software-properties-common (0.96.24.17) ...\n","Selecting previously unselected package unattended-upgrades.\n","Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n","Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n","Setting up python-apt-common (1.4.0~beta3build2) ...\n","Setting up python3-apt (1.4.0~beta3build2) ...\n","Setting up iso-codes (3.75-1) ...\n","Setting up distro-info-data (0.36ubuntu0.2) ...\n","Setting up python-pycurl (7.43.0-2build2) ...\n","Setting up lsb-release (9.20160110ubuntu5) ...\n","Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n","Setting up libkmod2:amd64 (24-1ubuntu2) ...\n","Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n","Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n","Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n","Setting up unattended-upgrades (0.98ubuntu1.1) ...\n","\n","Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n","\n","Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n","Setting up cron (3.0pl1-128ubuntu5) ...\n","Adding group `crontab' (GID 102) ...\n","Done.\n","update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n","update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n","Setting up kmod (24-1ubuntu2) ...\n","Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n","Setting up python3-gi (3.24.1-2build1) ...\n","Setting up module-init-tools (24-1ubuntu2) ...\n","Setting up python3-software-properties (0.96.24.17) ...\n","Setting up dbus (1.10.22-1ubuntu1) ...\n","Setting up python-apt (1.4.0~beta3build2) ...\n","Setting up python3-dbus (1.2.4-1build3) ...\n","Setting up python-software-properties (0.96.24.17) ...\n","Setting up software-properties-common (0.96.24.17) ...\n","Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n","Processing triggers for dbus (1.10.22-1ubuntu1) ...\n","gpg: keybox '/tmp/tmp8eucktvs/pubring.gpg' created\n","gpg: /tmp/tmp8eucktvs/trustdb.gpg: trustdb created\n","gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n","gpg: Total number processed: 1\n","gpg:               imported: 1\n","Warning: apt-key output should not be parsed (stdout is not a terminal)\n","Selecting previously unselected package libfuse2:amd64.\n","(Reading database ... 19839 files and directories currently installed.)\n","Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n","Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n","Selecting previously unselected package fuse.\n","Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n","Unpacking fuse (2.9.7-1ubuntu1) ...\n","Selecting previously unselected package google-drive-ocamlfuse.\n","Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n","Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n","Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n","Setting up fuse (2.9.7-1ubuntu1) ...\n","Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n"],"name":"stdout"}]},{"metadata":{"id":"r-rQdmjRIArz","colab_type":"code","colab":{}},"cell_type":"code","source":["# Colab 用の Auth token 成\n","from google.colab import auth\n","auth.authenticate_user()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oVhqR8gaIYYf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"05075a33-22e9-4c04-a644-9ad9eef275f7","executionInfo":{"status":"ok","timestamp":1534888937033,"user_tz":-540,"elapsed":14200,"user":{"displayName":"HARADA Tomohiko","photoUrl":"//lh3.googleusercontent.com/-NhVNZogeGbU/AAAAAAAAAAI/AAAAAAAAAB4/SUNHPkvUldw/s50-c-k-no/photo.jpg","userId":"102955192351597992804"}}},"cell_type":"code","source":["# Drive FUSE library 用の credential 生成\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"gYBRyqeiHWuB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ce1d033b-0788-4787-ad6a-485fb3f36a06","executionInfo":{"status":"ok","timestamp":1534888944498,"user_tz":-540,"elapsed":5815,"user":{"displayName":"HARADA Tomohiko","photoUrl":"//lh3.googleusercontent.com/-NhVNZogeGbU/AAAAAAAAAAI/AAAAAAAAAB4/SUNHPkvUldw/s50-c-k-no/photo.jpg","userId":"102955192351597992804"}}},"cell_type":"code","source":["# drive/ を作り, そこに Google Drive をマウントする\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","!ls \"drive/Colab Notebooks/kenkyu\""],"execution_count":6,"outputs":[{"output_type":"stream","text":["180715\t180818\r\n"],"name":"stdout"}]},{"metadata":{"id":"PywN5Q0fTxLJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"eb2cfd96-5d22-48c1-9f1e-d59a5050c09a","executionInfo":{"status":"ok","timestamp":1533955114044,"user_tz":-540,"elapsed":2186,"user":{"displayName":"HARADA Tomohiko","photoUrl":"//lh3.googleusercontent.com/-NhVNZogeGbU/AAAAAAAAAAI/AAAAAAAAAB4/SUNHPkvUldw/s50-c-k-no/photo.jpg","userId":"102955192351597992804"}}},"cell_type":"code","source":["!pip freeze | grep nltk"],"execution_count":0,"outputs":[{"output_type":"stream","text":["nltk==3.2.5\r\n"],"name":"stdout"}]},{"metadata":{"id":"DJpcv2-oT2Yy","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install -U nltk==3.2.5"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YRzrn2xJdvl9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"900faf2f-048a-4e72-d7a2-4cadf3b05c04","executionInfo":{"status":"ok","timestamp":1534888991810,"user_tz":-540,"elapsed":844,"user":{"displayName":"HARADA Tomohiko","photoUrl":"//lh3.googleusercontent.com/-NhVNZogeGbU/AAAAAAAAAAI/AAAAAAAAAB4/SUNHPkvUldw/s50-c-k-no/photo.jpg","userId":"102955192351597992804"}}},"cell_type":"code","source":["cd \"~/drive/Colab Notebooks/kenkyu/180818\""],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/drive/Colab Notebooks/kenkyu/180818\n"],"name":"stdout"}]},{"metadata":{"id":"4hBipaWUd00w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"37a9a928-12c8-482a-f01a-029f4653c887","executionInfo":{"status":"ok","timestamp":1534888999660,"user_tz":-540,"elapsed":2070,"user":{"displayName":"HARADA Tomohiko","photoUrl":"//lh3.googleusercontent.com/-NhVNZogeGbU/AAAAAAAAAAI/AAAAAAAAAB4/SUNHPkvUldw/s50-c-k-no/photo.jpg","userId":"102955192351597992804"}}},"cell_type":"code","source":["!ls"],"execution_count":12,"outputs":[{"output_type":"stream","text":["datasets  train_rnnlm-1.ipynb  train_rnnlm-2.ipynb\r\n"],"name":"stdout"}]},{"metadata":{"id":"cU8n_IaKE__X","colab_type":"code","colab":{}},"cell_type":"code","source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","\n","\"\"\" Sample script of recurrent neural network language model.\n","\n","    usage: python3.6 train_rnnlm.py --gpu -1 --epoch 200 --batchsize 100 --unit 300 --train datasets/soseki/neko-word-train.txt --test datasets/soseki/neko-word-test.txt --w2v datasets/soseki/neko_w2v.bin --out model-neko\n","    usage: python3.6  test_rnnlm.py --gpu -1 --model \"model-neko/final.model\" --text \"吾輩 は 猫 で ある 。\"\n","\"\"\"\n","\n","__version__ = '0.0.1'\n","\n","import sys, os, time, logging, json, math\n","import numpy as np\n","\n","np.set_printoptions(precision=20)\n","logger = logging.getLogger(__name__)\n","logger.setLevel(logging.DEBUG)\n","handler = logging.StreamHandler()\n","# handler = logging.FileHandler(filename=\"log.txt\")\n","handler.setFormatter(logging.Formatter('%(asctime)s - %(funcName)s - %(levelname)s - %(message)s'))\n","handler.setLevel(logging.DEBUG)\n","logger.addHandler(handler)\n","\n","\n","def pp(obj):\n","    import pprint\n","    pp = pprint.PrettyPrinter(indent=1, width=160)\n","    logger.info(pp.pformat(obj))\n","\n","\n","start_time = time.time()\n","\n","import chainer\n","from chainer import cuda\n","import chainer.functions as F\n","import chainer.links as L\n","import matplotlib.pyplot as plt\n","import pickle\n","from struct import unpack, calcsize\n","\n","# UNK_ID = 0\n","# EOS_ID = 1\n","# UNK_TOKEN = '<unk>'\n","EOS_TOKEN = '</s>'\n","\n","prime_text = \"\"\n","\n","\n","def load_w2v_model(path, vocab=[]):\n","    with open(path, 'rb') as f:\n","\n","        n_vocab, n_units = map(int, f.readline().split())\n","        M = np.empty((n_vocab, n_units), dtype=np.float32)\n","\n","        for i in range(n_vocab):\n","            b_str = b''\n","\n","            while True:\n","                b_ch = f.read(1)\n","                if b_ch == b' ':\n","                    break\n","                b_str += b_ch\n","\n","            token = b_str.decode(encoding='utf-8')\n","\n","            if token not in vocab:\n","                vocab += [token]\n","            else:\n","                logging.error(\"Duplicate token: {}\", token)\n","\n","            M[i] = np.zeros(n_units)\n","            for j in range(n_units):\n","                M[i][j] = unpack('f', f.read(calcsize('f')))[0]\n","\n","            # ベクトルを正規化する\n","            vlen = np.linalg.norm(M[i], 2)\n","            M[i] /= vlen\n","\n","            # 改行を strip する\n","            assert f.read(1) != '\\n'\n","\n","    return M, vocab\n","\n","\n","def load_data(filename, w2v, vocab, train=True):\n","    global prime_text\n","\n","    dataset = []\n","\n","    for i, line in enumerate(open(filename, 'r')):\n","        line = line.strip()\n","        tokens = line.split(' ') + [EOS_TOKEN]\n","\n","        if i == 0 and train:\n","            prime_text = line.split(' ')\n","\n","        for token in tokens:\n","            if token == '':\n","                continue\n","\n","            if train:\n","                if token not in vocab:\n","                    vocab += [token]\n","                    if w2v is not None:\n","                        v = np.random.uniform(-0.1, 0.1, (1, w2v.shape[1])).astype(np.float32)\n","                        v /= np.linalg.norm(v, 2)\n","                        w2v = np.vstack((w2v, v))\n","                    dataset.append(vocab.index(token))\n","                dataset.append(vocab.index(token))\n","            else:\n","                if token in vocab:\n","                    dataset.append(vocab.index(token))\n","\n","    return dataset, w2v, vocab\n","\n","\n","# Definition of a recurrent net for language modeling\n","class RNNLM(chainer.Chain):\n","\n","    def __init__(self, n_vocab, n_units):\n","        super(RNNLM, self).__init__()\n","        with self.init_scope():\n","            self.embed = L.EmbedID(n_vocab, n_units)\n","            self.l1 = L.LSTM(n_units, n_units)\n","            self.l2 = L.LSTM(n_units, n_units)\n","            self.l3 = L.Linear(n_units, n_vocab)\n","\n","        for param in self.params():\n","            param.data[...] = np.random.uniform(-0.1, 0.1, param.data.shape)\n","\n","    def __call__(self, x, t):\n","        y = self.forward(x)\n","        return F.softmax_cross_entropy(y, t), F.accuracy(y, t)\n","\n","    # 1ステップ前方処理関数 (学習データ,状態を与える)\n","    def forward(self, x):\n","        h0 = self.embed(x)\n","        h1 = self.l1(F.dropout(h0))\n","        h2 = self.l2(F.dropout(h1))\n","        y = self.l3(F.dropout(h2))\n","        return y\n","\n","    def predict(self, x):\n","        y = self.forward(x)\n","        return F.softmax(y)\n","\n","    # 状態の初期化 (初期状態を現在の状態にセット)\n","    def reset_state(self):\n","        self.l1.reset_state()\n","        self.l2.reset_state()\n","\n","    def set_word_embedding(self, data):\n","        self.embed.W.data = data\n","\n","\n","def show_sample(model, vocab, token2id, length=20, eos=EOS_TOKEN):\n","    model.reset_state()\n","\n","    for token in prime_text:\n","        sys.stdout.write(token)\n","        prev_word = model.predict(xp.array([token2id[token]], dtype=np.int32))\n","\n","    for i in range(length):\n","        next_prob = cuda.to_cpu(prev_word.data)[0].astype(np.float64)\n","        next_prob /= np.sum(next_prob)\n","        idx = np.random.choice(range(len(next_prob)), p=next_prob)\n","\n","        if vocab[idx] == EOS_TOKEN:\n","            sys.stdout.write(eos)\n","        else:\n","            sys.stdout.write(vocab[idx])\n","        prev_word = model.predict(xp.array([idx], dtype=np.int32))\n","\n","    sys.stdout.write('\\n')\n","\n","\n","def main():\n","    global xp\n","\n","    import argparse\n","    parser = argparse.ArgumentParser(description='Chainer example: RNNLM')\n","    parser.add_argument('--train', default='datasets/soseki/neko-word-train.txt', type=str, help='dataset to train (.txt)')\n","    parser.add_argument('--test', default='datasets/soseki/neko-word-test.txt', type=str, help='use tiny datasets to evaluate (.txt)')\n","    parser.add_argument('--w2v', '-w', default='datasets/soseki/neko_w2v.bin', type=str, help='initialize word embedding layer with word2vec (.bin)')\n","    parser.add_argument('--batchsize', '-b', type=int, default=100, help='number of examples in each mini-batch')\n","    parser.add_argument('--bproplen', '-l', type=int, default=35, help='number of words in each mini-batch (= length of truncated BPTT)')\n","    parser.add_argument('--epoch', '-e', type=int, default=300, help='number of sweeps over the dataset to train')\n","    parser.add_argument('--unit', '-u', type=int, default=200, help='number of LSTM units in each layer')\n","    parser.add_argument('--gpu', '-g', type=int, default=0, help='GPU ID (negative value indicates CPU)')\n","    parser.add_argument('--gradclip', '-c', type=float, default=5, help='Gradient norm threshold to clip')\n","    parser.add_argument('--out', '-o', default='results_rnnlm-2', help='Directory to output the result')\n","    parser.add_argument('--resume', '-r', default='', help='resume the training from snapshot')\n","    args = parser.parse_args(args=[])\n","#     args = parser.parse_args()\n","    print(json.dumps(args.__dict__, indent=2))\n","    sys.stdout.flush()\n","\n","    if args.gpu >= 0:\n","        cuda.get_device_from_id(args.gpu).use()\n","\n","    xp = cuda.cupy if args.gpu >= 0 else np\n","    xp.random.seed(123)\n","\n","    w2v, vocab, n_dims = None, [], args.unit\n","\n","    if args.w2v:\n","        w2v, vocab = load_w2v_model(args.w2v)\n","        n_dims = w2v.shape[1]\n","\n","    if args.test:\n","        train_data, w2v, vocab = load_data(args.train, w2v, vocab, train=True)\n","        test_data,  w2v, vocab = load_data(args.test,  w2v, vocab, train=False)\n","    else:\n","        dataset, w2v, vocab = load_data(args.train, w2v, vocab, train=True)\n","        train_data = dataset[:-1000]\n","        test_data  = dataset[-1000:]\n","\n","    token2id = {w: i for i, w in enumerate(vocab)}\n","\n","    logger.info('vocabulary size: %d' % len(vocab))\n","    logger.info('train data size: %d' % len(train_data))\n","    logger.info('train data starts with: {} ...'.format(' '.join(prime_text)))\n","    logger.info('test  data size: %d' % len(test_data))\n","    sys.stdout.flush()\n","\n","    if not os.path.exists(args.out):\n","        os.mkdir(args.out)\n","\n","    with open(os.path.join(args.out, 'vocab.bin'), 'wb') as f:\n","        pickle.dump(vocab, f)\n","\n","    # Recurrent neural net languabe model\n","    model = RNNLM(len(vocab), n_dims)\n","\n","    # 学習率\n","    lr = 0.0007\n","\n","    # 重み減衰\n","    decay = 0.0005\n","\n","    # 学習率の減衰\n","    lr_decay = 0.995\n","\n","    # Setup optimizer (Optimizer の設定)\n","    optimizer = chainer.optimizers.Adam(alpha=lr)\n","    # optimizer = optimizers.AdaDelta()\n","    optimizer.setup(model)\n","    optimizer.add_hook(chainer.optimizer.GradientClipping(args.gradclip))\n","    optimizer.add_hook(chainer.optimizer.WeightDecay(decay))\n","\n","    # Resume the training from snapshot\n","    if args.resume:\n","        print('Resume the training from snapshot: {0}.{{model,state}}'.format(args.resume))\n","        chainer.serializers.load_npz('{}.model'.format(args.resume), model)\n","        chainer.serializers.load_npz('{}.state'.format(args.resume), optimizer, strict=False)\n","        sys.stdout.flush()\n","\n","    # Initialize word embedding layer with word2vec\n","    if not args.resume and args.w2v:\n","        print('Initialize the embedding from word2vec model: {}'.format(args.w2v))\n","        model.set_word_embedding(w2v)\n","\n","    if args.gpu >= 0:\n","        model.to_gpu(args.gpu)\n","\n","    # プロット用に実行結果を保存する\n","    train_loss = []\n","    train_accuracy1 = []\n","    train_accuracy2 = []\n","    test_loss = []\n","    test_accuracy1 = []\n","    test_accuracy2 = []\n","    min_loss = float('inf')\n","    min_epoch = 0\n","\n","    # ストライド幅を計算する\n","    train_stride = len(train_data) // args.batchsize\n","    test_stride = len(test_data) // args.batchsize\n","\n","    # 最初の時間情報を取得する\n","    start_at = time.time()\n","    cur_at = start_at\n","\n","    # Learning loop\n","    print(\"going to train {} iterations ({} epochs)\".format(train_stride * args.epoch, args.epoch))\n","\n","    # training\n","    epoch = 1\n","    accum_loss = None\n","\n","    sum_train_loss = 0.\n","    sum_train_accuracy1 = 0.\n","    sum_train_accuracy2 = 0.\n","    K = 0\n","\n","    # RNN 状態を初期化する\n","    model.reset_state()\n","\n","    for iteration in range(train_stride * args.epoch):\n","\n","        # logger.info('epoch {:} / {:}'.format(epoch, n_epoch))\n","        # handler1.flush()\n","\n","        x_batch = xp.array([train_data[(train_stride * x + iteration) % len(train_data)] for x in range(args.batchsize)])\n","        y_batch = xp.array([train_data[(train_stride * x + iteration + 1) % len(train_data)] for x in range(args.batchsize)])\n","\n","        # 順伝播させて誤差と精度を算出\n","        loss, accuracy = model(x_batch, y_batch)\n","        accum_loss = loss if accum_loss is None else accum_loss + loss\n","        sum_train_loss += float(loss.data)\n","        sum_train_accuracy1 += float(accuracy.data)\n","        sum_train_accuracy2 += math.exp(float(loss.data))\n","        K += 1\n","\n","        # 誤差逆伝播で勾配を計算 (bproplen ごと)\n","        if (iteration + 1) % args.bproplen == 0:\n","            model.cleargrads()\n","            accum_loss.backward()\n","            accum_loss.unchain_backward()\n","            optimizer.update()\n","\n","        # 訓練データの誤差と,正解精度を表示 (epoch ごと)\n","        if (iteration + 1) % train_stride == 0:\n","            mean_train_loss = sum_train_loss / K\n","            mean_train_accuracy1 = sum_train_accuracy1 / K\n","            mean_train_accuracy2 = sum_train_accuracy2 / K\n","            train_loss.append(mean_train_loss)\n","            train_accuracy1.append(mean_train_accuracy1)\n","            train_accuracy2.append(mean_train_accuracy2)\n","            now = time.time()\n","            train_throughput = now - cur_at\n","            cur_at = now\n","\n","            # evaluation\n","            sum_test_loss = 0.\n","            sum_test_accuracy1 = 0.\n","            sum_test_accuracy2 = 0.\n","            K = 0\n","\n","            # RNN 状態を初期化する\n","            model.reset_state()\n","\n","            with chainer.no_backprop_mode(), chainer.using_config('train', False):\n","                for i in range(test_stride):\n","                    x_batch = xp.array([test_data[(test_stride * x + iteration) % len(test_data)] for x in range(args.batchsize)])\n","                    y_batch = xp.array([test_data[(test_stride * x + iteration + 1) % len(test_data)] for x in range(args.batchsize)])\n","\n","                    # 順伝播させて誤差と精度を算出\n","                    loss, accuracy = model(x_batch, y_batch)\n","                    accum_loss = loss if accum_loss is None else accum_loss + loss\n","                    sum_test_loss += float(loss.data)\n","                    sum_test_accuracy1 += float(accuracy.data)\n","                    sum_test_accuracy2 += math.exp(float(loss.data))\n","                    K += 1\n","\n","            # テストデータでの誤差と正解精度を表示\n","            mean_test_loss = sum_test_loss / K\n","            mean_test_accuracy1 = sum_test_accuracy1 / K\n","            mean_test_accuracy2 = sum_test_accuracy2 / K\n","            test_loss.append(mean_test_loss)\n","            test_accuracy1.append(mean_test_accuracy1)\n","            test_accuracy2.append(mean_test_accuracy2)\n","            now = time.time()\n","            test_throughput = now - cur_at\n","\n","            logger.info(''\n","                        '[{:>3d}] '\n","                        'T/loss={:.6f} '\n","                        'T/acc={:.6f} '\n","                        'T/perp={:.6f} '\n","                        'T/sec= {:.6f} '\n","                        'D/loss={:.6f} '\n","                        'D/acc={:.6f} '\n","                        'D/perp={:.6f} '\n","                        'D/sec= {:.6f} '\n","                        'lr={:.6f}'\n","                        ''.format(\n","                epoch,\n","                mean_train_loss,\n","                mean_train_accuracy1,\n","                mean_train_accuracy2,\n","                train_throughput,\n","                mean_test_loss,\n","                mean_test_accuracy1,\n","                mean_test_accuracy2,\n","                test_throughput,\n","                optimizer.alpha)\n","            )\n","            sys.stdout.flush()\n","\n","            # model と optimizer を保存する\n","            if mean_train_loss < min_loss:\n","                min_loss = mean_train_loss\n","                min_epoch = epoch\n","                if args.gpu >= 0: model.to_cpu()\n","                chainer.serializers.save_npz(os.path.join(args.out, 'early_stopped.model'), model)\n","                chainer.serializers.save_npz(os.path.join(args.out, 'early_stopped.state'), optimizer)\n","                if args.gpu >= 0: model.to_gpu()\n","\n","            print(\"SAMPLE #=> \", end='')\n","            with chainer.no_backprop_mode(), chainer.using_config('train', False):\n","                show_sample(model.copy(), vocab, token2id)\n","            sys.stdout.flush()\n","\n","            # 精度と誤差をグラフ描画\n","            if True:\n","                ylim1 = [min(train_loss + train_accuracy2 + test_loss + test_accuracy2), max(train_loss + train_accuracy2 + test_loss + test_accuracy2)]\n","                ylim2 = [min(train_accuracy1 + test_accuracy1), max(train_accuracy1 + test_accuracy1)]\n","\n","                # グラフ左\n","                plt.figure(figsize=(10, 10))\n","                plt.subplot(1, 2, 1)\n","                plt.ylim(ylim1)\n","                plt.plot(range(1, len(train_loss) + 1), train_loss, 'b')\n","                plt.plot(range(1, len(train_accuracy2) + 1), train_accuracy2, 'm')\n","                plt.grid(False)\n","                plt.ylabel('loss and perplexity')\n","                plt.legend(['train loss', 'train perplexity'], loc=\"lower left\")\n","                plt.twinx()\n","                plt.ylim(ylim2)\n","                plt.plot(range(1, len(train_accuracy1) + 1), train_accuracy1, 'r')\n","                plt.grid(False)\n","                # plt.ylabel('accuracy')\n","                plt.legend(['train accuracy'], loc=\"upper right\")\n","                plt.title('Loss and accuracy for train data.')\n","\n","                # グラフ右\n","                plt.subplot(1, 2, 2)\n","                plt.ylim(ylim1)\n","                plt.plot(range(1, len(test_loss) + 1), test_loss, 'b')\n","                plt.plot(range(1, len(test_accuracy2) + 1), test_accuracy2, 'm')\n","                plt.grid(False)\n","                # plt.ylabel('loss and perplexity')\n","                plt.legend(['test loss', 'test perplexity'], loc=\"lower left\")\n","                plt.twinx()\n","                plt.ylim(ylim2)\n","                plt.plot(range(1, len(test_accuracy1) + 1), test_accuracy1, 'r')\n","                plt.grid(False)\n","                plt.ylabel('accuracy')\n","                plt.legend(['test accuracy'], loc=\"upper right\")\n","                plt.title('Loss and accuracy for test data.')\n","\n","                plt.savefig('{}.png'.format(args.out))\n","#                 plt.savefig('{}.png'.format(os.path.splitext(os.path.basename(__file__))[0]))\n","                # plt.show()\n","\n","            optimizer.alpha *= lr_decay\n","            cur_at = now\n","\n","            epoch += 1\n","            sum_train_loss = 0.\n","            sum_train_accuracy1 = 0.\n","            sum_train_accuracy2 = 0.\n","            K = 0\n","\n","    # model と optimizer を保存する\n","    if args.gpu >= 0: model.to_cpu()\n","    chainer.serializers.save_npz(os.path.join(args.out, 'final.model'), model)\n","    chainer.serializers.save_npz(os.path.join(args.out, 'final.state'), optimizer)\n","    if args.gpu >= 0: model.to_gpu()\n","\n","    # test\n","    print('loading early stopped-model at epoch {}'.format(min_epoch))\n","    chainer.serializers.load_npz(os.path.join(args.out, 'early_stopped.model'), model)\n","    sys.stdout.flush()\n","\n","    vocab = pickle.load(open(os.path.join(args.out, 'vocab.bin'), 'rb'))\n","    token2id = {}\n","    for i, token in enumerate(vocab):\n","        token2id[token] = i\n","\n","    with chainer.no_backprop_mode(), chainer.using_config('train', False):\n","        show_sample(model, vocab, token2id, length=500, eos=\"\\n\")\n","\n","    logger.info('time spent: {:.6f} sec\\n'.format(time.time() - start_time))\n","\n","    \n","if __name__ == '__main__':\n","    main()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DXtHrWcac6dx","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls -al ~/.local/share/jupyter/runtime"],"execution_count":0,"outputs":[]}]}