{
  "gpu": 0,
  "batchsize": 32,
  "learnrate": 5e-05,
  "weightdecay": 0.01,
  "epoch": 50,
  "train": "../datasets/rt-polarity/04-train.txt",
  "eval": "../datasets/rt-polarity/04-test.txt",
  "init_checkpoint": "../../BERT/uncased_L-12_H-768_A-12/arrays_bert_model.ckpt.npz",
  "bert_config_file": "../../BERT/uncased_L-12_H-768_A-12/bert_config.json",
  "vocab_file": "../../BERT/uncased_L-12_H-768_A-12/vocab.txt",
  "out": "results_bert-2-rt",
  "resume": "",
  "start_epoch": 1,
  "noplot": false
}
WARNING: Logging before flag parsing goes to stderr.
W0816 00:15:52.237947 139794510784384 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/kenkyu/190816/bertlib/tokenization.py:74: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

2019-08-16 00:15:57,399 - load_data - INFO - Loading dataset ... done.
I0816 00:15:57.399362 139794510784384 <ipython-input-7-90da46432566>:79] Loading dataset ... done.
2019-08-16 00:15:58,262 - load_data - INFO - Loading dataset ... done.
I0816 00:15:58.262384 139794510784384 <ipython-input-7-90da46432566>:79] Loading dataset ... done.
# train: 9596, eval: 1066,
# class: 2, labels: {'0': 0, '1': 1}
# vocab: 30522
2019-08-16 00:21:09,383 - main - INFO - [  1] T/loss=0.397143 T/acc1=0.825552 T/acc2=0.000000 T/sec= 270.508771 D/loss=0.312218 D/acc1=0.873358 D/acc2=0.873358 D/sec= 16.910139 lr=0.509208 eta=0.000050
I0816 00:21:09.383604 139794510784384 <ipython-input-7-90da46432566>:373] [  1] T/loss=0.397143 T/acc1=0.825552 T/acc2=0.000000 T/sec= 270.508771 D/loss=0.312218 D/acc1=0.873358 D/acc2=0.873358 D/sec= 16.910139 lr=0.509208 eta=0.000050
saving early-stopped model (loss) at epoch 1
saving early-stopped model (uar) at epoch 1
2019-08-16 00:28:26,624 - main - INFO - [  2] T/loss=0.193262 T/acc1=0.930075 T/acc2=0.000000 T/sec= 420.337496 D/loss=0.355167 D/acc1=0.869606 D/acc2=0.869606 D/sec= 16.903430 lr=0.671828 eta=0.000049
I0816 00:28:26.624545 139794510784384 <ipython-input-7-90da46432566>:373] [  2] T/loss=0.193262 T/acc1=0.930075 T/acc2=0.000000 T/sec= 420.337496 D/loss=0.355167 D/acc1=0.869606 D/acc2=0.869606 D/sec= 16.903430 lr=0.671828 eta=0.000049
2019-08-16 00:34:13,282 - main - INFO - [  3] T/loss=0.094704 T/acc1=0.969675 T/acc2=0.000000 T/sec= 329.799550 D/loss=0.522871 D/acc1=0.866792 D/acc2=0.866792 D/sec= 16.858395 lr=0.770463 eta=0.000048
I0816 00:34:13.282470 139794510784384 <ipython-input-7-90da46432566>:373] [  3] T/loss=0.094704 T/acc1=0.969675 T/acc2=0.000000 T/sec= 329.799550 D/loss=0.522871 D/acc1=0.866792 D/acc2=0.866792 D/sec= 16.858395 lr=0.770463 eta=0.000048
2019-08-16 00:40:00,747 - main - INFO - [  4] T/loss=0.054876 T/acc1=0.985619 T/acc2=0.000000 T/sec= 330.592880 D/loss=0.676829 D/acc1=0.865854 D/acc2=0.865854 D/sec= 16.872372 lr=0.836054 eta=0.000047
I0816 00:40:00.747720 139794510784384 <ipython-input-7-90da46432566>:373] [  4] T/loss=0.054876 T/acc1=0.985619 T/acc2=0.000000 T/sec= 330.592880 D/loss=0.676829 D/acc1=0.865854 D/acc2=0.865854 D/sec= 16.872372 lr=0.836054 eta=0.000047
2019-08-16 00:45:47,744 - main - INFO - [  5] T/loss=0.044447 T/acc1=0.989266 T/acc2=0.000000 T/sec= 330.157954 D/loss=0.820141 D/acc1=0.852720 D/acc2=0.852720 D/sec= 16.838714 lr=0.881497 eta=0.000046
I0816 00:45:47.744398 139794510784384 <ipython-input-7-90da46432566>:373] [  5] T/loss=0.044447 T/acc1=0.989266 T/acc2=0.000000 T/sec= 330.157954 D/loss=0.820141 D/acc1=0.852720 D/acc2=0.852720 D/sec= 16.838714 lr=0.881497 eta=0.000046
2019-08-16 00:51:35,048 - main - INFO - [  6] T/loss=0.029457 T/acc1=0.993226 T/acc2=0.000000 T/sec= 330.370900 D/loss=0.777803 D/acc1=0.859287 D/acc2=0.859287 D/sec= 16.933253 lr=0.913701 eta=0.000045
I0816 00:51:35.048582 139794510784384 <ipython-input-7-90da46432566>:373] [  6] T/loss=0.029457 T/acc1=0.993226 T/acc2=0.000000 T/sec= 330.370900 D/loss=0.777803 D/acc1=0.859287 D/acc2=0.859287 D/sec= 16.933253 lr=0.913701 eta=0.000045
2019-08-16 00:57:21,573 - main - INFO - [  7] T/loss=0.023292 T/acc1=0.994373 T/acc2=0.000000 T/sec= 329.645627 D/loss=0.893888 D/acc1=0.857411 D/acc2=0.857411 D/sec= 16.879592 lr=0.936842 eta=0.000044
I0816 00:57:21.573759 139794510784384 <ipython-input-7-90da46432566>:373] [  7] T/loss=0.023292 T/acc1=0.994373 T/acc2=0.000000 T/sec= 329.645627 D/loss=0.893888 D/acc1=0.857411 D/acc2=0.857411 D/sec= 16.879592 lr=0.936842 eta=0.000044
2019-08-16 01:03:08,586 - main - INFO - [  8] T/loss=0.023939 T/acc1=0.995311 T/acc2=0.000000 T/sec= 330.096704 D/loss=0.824965 D/acc1=0.872420 D/acc2=0.872420 D/sec= 16.915851 lr=0.953620 eta=0.000043
I0816 01:03:08.586323 139794510784384 <ipython-input-7-90da46432566>:373] [  8] T/loss=0.023939 T/acc1=0.995311 T/acc2=0.000000 T/sec= 330.096704 D/loss=0.824965 D/acc1=0.872420 D/acc2=0.872420 D/sec= 16.915851 lr=0.953620 eta=0.000043
2019-08-16 01:08:55,980 - main - INFO - [  9] T/loss=0.026288 T/acc1=0.993643 T/acc2=0.000000 T/sec= 330.484925 D/loss=0.848936 D/acc1=0.869606 D/acc2=0.869606 D/sec= 16.909221 lr=0.965860 eta=0.000042
I0816 01:08:55.980462 139794510784384 <ipython-input-7-90da46432566>:373] [  9] T/loss=0.026288 T/acc1=0.993643 T/acc2=0.000000 T/sec= 330.484925 D/loss=0.848936 D/acc1=0.869606 D/acc2=0.869606 D/sec= 16.909221 lr=0.965860 eta=0.000042
2019-08-16 01:14:42,716 - main - INFO - [ 10] T/loss=0.021902 T/acc1=0.995519 T/acc2=0.000000 T/sec= 329.816586 D/loss=0.860092 D/acc1=0.862101 D/acc2=0.862101 D/sec= 16.919760 lr=0.974827 eta=0.000041
I0816 01:14:42.716862 139794510784384 <ipython-input-7-90da46432566>:373] [ 10] T/loss=0.021902 T/acc1=0.995519 T/acc2=0.000000 T/sec= 329.816586 D/loss=0.860092 D/acc1=0.862101 D/acc2=0.862101 D/sec= 16.919760 lr=0.974827 eta=0.000041
2019-08-16 01:20:28,752 - main - INFO - [ 11] T/loss=0.016813 T/acc1=0.996561 T/acc2=0.000000 T/sec= 329.128548 D/loss=0.861759 D/acc1=0.868668 D/acc2=0.868668 D/sec= 16.907040 lr=0.981416 eta=0.000040
I0816 01:20:28.752405 139794510784384 <ipython-input-7-90da46432566>:373] [ 11] T/loss=0.016813 T/acc1=0.996561 T/acc2=0.000000 T/sec= 329.128548 D/loss=0.861759 D/acc1=0.868668 D/acc2=0.868668 D/sec= 16.907040 lr=0.981416 eta=0.000040
2019-08-16 01:26:15,386 - main - INFO - [ 12] T/loss=0.022189 T/acc1=0.994894 T/acc2=0.000000 T/sec= 329.722107 D/loss=0.835495 D/acc1=0.878049 D/acc2=0.878049 D/sec= 16.911511 lr=0.986268 eta=0.000039
I0816 01:26:15.386030 139794510784384 <ipython-input-7-90da46432566>:373] [ 12] T/loss=0.022189 T/acc1=0.994894 T/acc2=0.000000 T/sec= 329.722107 D/loss=0.835495 D/acc1=0.878049 D/acc2=0.878049 D/sec= 16.911511 lr=0.986268 eta=0.000039
saving early-stopped model (uar) at epoch 12
2019-08-16 01:32:29,760 - main - INFO - [ 13] T/loss=0.015602 T/acc1=0.996457 T/acc2=0.000000 T/sec= 357.488466 D/loss=0.898948 D/acc1=0.879925 D/acc2=0.879925 D/sec= 16.885515 lr=0.989847 eta=0.000038
I0816 01:32:29.760056 139794510784384 <ipython-input-7-90da46432566>:373] [ 13] T/loss=0.015602 T/acc1=0.996457 T/acc2=0.000000 T/sec= 357.488466 D/loss=0.898948 D/acc1=0.879925 D/acc2=0.879925 D/sec= 16.885515 lr=0.989847 eta=0.000038
saving early-stopped model (uar) at epoch 13
2019-08-16 01:38:43,282 - main - INFO - [ 14] T/loss=0.011589 T/acc1=0.997082 T/acc2=0.000000 T/sec= 356.591275 D/loss=1.007868 D/acc1=0.863977 D/acc2=0.863977 D/sec= 16.931039 lr=0.992490 eta=0.000037
I0816 01:38:43.282324 139794510784384 <ipython-input-7-90da46432566>:373] [ 14] T/loss=0.011589 T/acc1=0.997082 T/acc2=0.000000 T/sec= 356.591275 D/loss=1.007868 D/acc1=0.863977 D/acc2=0.863977 D/sec= 16.931039 lr=0.992490 eta=0.000037
2019-08-16 01:44:29,409 - main - INFO - [ 15] T/loss=0.014427 T/acc1=0.997291 T/acc2=0.000000 T/sec= 329.234705 D/loss=0.721208 D/acc1=0.878049 D/acc2=0.878049 D/sec= 16.892179 lr=0.994443 eta=0.000036
I0816 01:44:29.409205 139794510784384 <ipython-input-7-90da46432566>:373] [ 15] T/loss=0.014427 T/acc1=0.997291 T/acc2=0.000000 T/sec= 329.234705 D/loss=0.721208 D/acc1=0.878049 D/acc2=0.878049 D/sec= 16.892179 lr=0.994443 eta=0.000036
2019-08-16 01:50:15,938 - main - INFO - [ 16] T/loss=0.012642 T/acc1=0.997291 T/acc2=0.000000 T/sec= 329.635834 D/loss=0.900063 D/acc1=0.870544 D/acc2=0.870544 D/sec= 16.893575 lr=0.995887 eta=0.000035
I0816 01:50:15.938610 139794510784384 <ipython-input-7-90da46432566>:373] [ 16] T/loss=0.012642 T/acc1=0.997291 T/acc2=0.000000 T/sec= 329.635834 D/loss=0.900063 D/acc1=0.870544 D/acc2=0.870544 D/sec= 16.893575 lr=0.995887 eta=0.000035
2019-08-16 01:56:03,689 - main - INFO - [ 17] T/loss=0.013815 T/acc1=0.997291 T/acc2=0.000000 T/sec= 330.861585 D/loss=0.948444 D/acc1=0.858349 D/acc2=0.858349 D/sec= 16.889760 lr=0.996955 eta=0.000034
I0816 01:56:03.689950 139794510784384 <ipython-input-7-90da46432566>:373] [ 17] T/loss=0.013815 T/acc1=0.997291 T/acc2=0.000000 T/sec= 330.861585 D/loss=0.948444 D/acc1=0.858349 D/acc2=0.858349 D/sec= 16.889760 lr=0.996955 eta=0.000034
2019-08-16 02:01:50,963 - main - INFO - [ 18] T/loss=0.010844 T/acc1=0.997707 T/acc2=0.000000 T/sec= 330.386446 D/loss=0.916968 D/acc1=0.880863 D/acc2=0.880863 D/sec= 16.887196 lr=0.997745 eta=0.000033
I0816 02:01:50.963587 139794510784384 <ipython-input-7-90da46432566>:373] [ 18] T/loss=0.010844 T/acc1=0.997707 T/acc2=0.000000 T/sec= 330.386446 D/loss=0.916968 D/acc1=0.880863 D/acc2=0.880863 D/sec= 16.887196 lr=0.997745 eta=0.000033
saving early-stopped model (uar) at epoch 18
2019-08-16 02:08:04,101 - main - INFO - [ 19] T/loss=0.011602 T/acc1=0.997812 T/acc2=0.000000 T/sec= 356.216918 D/loss=0.798517 D/acc1=0.882739 D/acc2=0.882739 D/sec= 16.920960 lr=0.998330 eta=0.000032
I0816 02:08:04.101497 139794510784384 <ipython-input-7-90da46432566>:373] [ 19] T/loss=0.011602 T/acc1=0.997812 T/acc2=0.000000 T/sec= 356.216918 D/loss=0.798517 D/acc1=0.882739 D/acc2=0.882739 D/sec= 16.920960 lr=0.998330 eta=0.000032
saving early-stopped model (uar) at epoch 19
2019-08-16 02:14:19,119 - main - INFO - [ 20] T/loss=0.004748 T/acc1=0.998854 T/acc2=0.000000 T/sec= 358.109070 D/loss=1.020414 D/acc1=0.869606 D/acc2=0.869606 D/sec= 16.909370 lr=0.998764 eta=0.000031
I0816 02:14:19.119951 139794510784384 <ipython-input-7-90da46432566>:373] [ 20] T/loss=0.004748 T/acc1=0.998854 T/acc2=0.000000 T/sec= 358.109070 D/loss=1.020414 D/acc1=0.869606 D/acc2=0.869606 D/sec= 16.909370 lr=0.998764 eta=0.000031
2019-08-16 02:20:06,259 - main - INFO - [ 21] T/loss=0.008556 T/acc1=0.998124 T/acc2=0.000000 T/sec= 330.211706 D/loss=1.041075 D/acc1=0.869606 D/acc2=0.869606 D/sec= 16.927547 lr=0.999084 eta=0.000030
I0816 02:20:06.259170 139794510784384 <ipython-input-7-90da46432566>:373] [ 21] T/loss=0.008556 T/acc1=0.998124 T/acc2=0.000000 T/sec= 330.211706 D/loss=1.041075 D/acc1=0.869606 D/acc2=0.869606 D/sec= 16.927547 lr=0.999084 eta=0.000030
2019-08-16 02:25:52,735 - main - INFO - [ 22] T/loss=0.008412 T/acc1=0.998437 T/acc2=0.000000 T/sec= 329.546613 D/loss=0.955438 D/acc1=0.877111 D/acc2=0.877111 D/sec= 16.930006 lr=0.999322 eta=0.000029
I0816 02:25:52.735803 139794510784384 <ipython-input-7-90da46432566>:373] [ 22] T/loss=0.008412 T/acc1=0.998437 T/acc2=0.000000 T/sec= 329.546613 D/loss=0.955438 D/acc1=0.877111 D/acc2=0.877111 D/sec= 16.930006 lr=0.999322 eta=0.000029
2019-08-16 02:31:39,808 - main - INFO - [ 23] T/loss=0.004515 T/acc1=0.998958 T/acc2=0.000000 T/sec= 330.117970 D/loss=1.060462 D/acc1=0.880863 D/acc2=0.880863 D/sec= 16.954297 lr=0.999498 eta=0.000028
I0816 02:31:39.808065 139794510784384 <ipython-input-7-90da46432566>:373] [ 23] T/loss=0.004515 T/acc1=0.998958 T/acc2=0.000000 T/sec= 330.117970 D/loss=1.060462 D/acc1=0.880863 D/acc2=0.880863 D/sec= 16.954297 lr=0.999498 eta=0.000028
2019-08-16 02:37:27,706 - main - INFO - [ 24] T/loss=0.006115 T/acc1=0.998958 T/acc2=0.000000 T/sec= 330.980824 D/loss=1.042402 D/acc1=0.867730 D/acc2=0.867730 D/sec= 16.918078 lr=0.999628 eta=0.000027
I0816 02:37:27.706957 139794510784384 <ipython-input-7-90da46432566>:373] [ 24] T/loss=0.006115 T/acc1=0.998958 T/acc2=0.000000 T/sec= 330.980824 D/loss=1.042402 D/acc1=0.867730 D/acc2=0.867730 D/sec= 16.918078 lr=0.999628 eta=0.000027
2019-08-16 02:43:14,673 - main - INFO - [ 25] T/loss=0.012059 T/acc1=0.996874 T/acc2=0.000000 T/sec= 330.071395 D/loss=0.942928 D/acc1=0.880863 D/acc2=0.880863 D/sec= 16.894714 lr=0.999724 eta=0.000026
I0816 02:43:14.673085 139794510784384 <ipython-input-7-90da46432566>:373] [ 25] T/loss=0.012059 T/acc1=0.996874 T/acc2=0.000000 T/sec= 330.071395 D/loss=0.942928 D/acc1=0.880863 D/acc2=0.880863 D/sec= 16.894714 lr=0.999724 eta=0.000026
2019-08-16 02:49:02,764 - main - INFO - [ 26] T/loss=0.005203 T/acc1=0.999062 T/acc2=0.000000 T/sec= 331.179299 D/loss=1.140152 D/acc1=0.876173 D/acc2=0.876173 D/sec= 16.911797 lr=0.999796 eta=0.000025
I0816 02:49:02.764151 139794510784384 <ipython-input-7-90da46432566>:373] [ 26] T/loss=0.005203 T/acc1=0.999062 T/acc2=0.000000 T/sec= 331.179299 D/loss=1.140152 D/acc1=0.876173 D/acc2=0.876173 D/sec= 16.911797 lr=0.999796 eta=0.000025
2019-08-16 02:54:51,609 - main - INFO - [ 27] T/loss=0.004421 T/acc1=0.999271 T/acc2=0.000000 T/sec= 331.921412 D/loss=1.072430 D/acc1=0.869606 D/acc2=0.869606 D/sec= 16.924328 lr=0.999849 eta=0.000024
I0816 02:54:51.609894 139794510784384 <ipython-input-7-90da46432566>:373] [ 27] T/loss=0.004421 T/acc1=0.999271 T/acc2=0.000000 T/sec= 331.921412 D/loss=1.072430 D/acc1=0.869606 D/acc2=0.869606 D/sec= 16.924328 lr=0.999849 eta=0.000024
2019-08-16 03:00:38,887 - main - INFO - [ 28] T/loss=0.002438 T/acc1=0.999687 T/acc2=0.000000 T/sec= 330.371990 D/loss=1.069018 D/acc1=0.879925 D/acc2=0.879925 D/sec= 16.905166 lr=0.999888 eta=0.000023
I0816 03:00:38.887077 139794510784384 <ipython-input-7-90da46432566>:373] [ 28] T/loss=0.002438 T/acc1=0.999687 T/acc2=0.000000 T/sec= 330.371990 D/loss=1.069018 D/acc1=0.879925 D/acc2=0.879925 D/sec= 16.905166 lr=0.999888 eta=0.000023
2019-08-16 03:06:27,604 - main - INFO - [ 29] T/loss=0.005741 T/acc1=0.998854 T/acc2=0.000000 T/sec= 331.833937 D/loss=1.058817 D/acc1=0.876173 D/acc2=0.876173 D/sec= 16.883866 lr=0.999917 eta=0.000022
I0816 03:06:27.604862 139794510784384 <ipython-input-7-90da46432566>:373] [ 29] T/loss=0.005741 T/acc1=0.998854 T/acc2=0.000000 T/sec= 331.833937 D/loss=1.058817 D/acc1=0.876173 D/acc2=0.876173 D/sec= 16.883866 lr=0.999917 eta=0.000022
2019-08-16 03:12:16,458 - main - INFO - [ 30] T/loss=0.002826 T/acc1=0.999479 T/acc2=0.000000 T/sec= 331.914541 D/loss=1.109903 D/acc1=0.883677 D/acc2=0.883677 D/sec= 16.938877 lr=0.999939 eta=0.000021
I0816 03:12:16.458364 139794510784384 <ipython-input-7-90da46432566>:373] [ 30] T/loss=0.002826 T/acc1=0.999479 T/acc2=0.000000 T/sec= 331.914541 D/loss=1.109903 D/acc1=0.883677 D/acc2=0.883677 D/sec= 16.938877 lr=0.999939 eta=0.000021
saving early-stopped model (uar) at epoch 30
2019-08-16 03:18:32,690 - main - INFO - [ 31] T/loss=0.000445 T/acc1=0.999896 T/acc2=0.000000 T/sec= 359.349904 D/loss=1.180464 D/acc1=0.878987 D/acc2=0.878987 D/sec= 16.882221 lr=0.999954 eta=0.000020
I0816 03:18:32.690408 139794510784384 <ipython-input-7-90da46432566>:373] [ 31] T/loss=0.000445 T/acc1=0.999896 T/acc2=0.000000 T/sec= 359.349904 D/loss=1.180464 D/acc1=0.878987 D/acc2=0.878987 D/sec= 16.882221 lr=0.999954 eta=0.000020
2019-08-16 03:24:20,960 - main - INFO - [ 32] T/loss=0.000004 T/acc1=1.000000 T/acc2=0.000000 T/sec= 331.378917 D/loss=1.196067 D/acc1=0.881801 D/acc2=0.881801 D/sec= 16.891350 lr=0.999966 eta=0.000019
I0816 03:24:20.960669 139794510784384 <ipython-input-7-90da46432566>:373] [ 32] T/loss=0.000004 T/acc1=1.000000 T/acc2=0.000000 T/sec= 331.378917 D/loss=1.196067 D/acc1=0.881801 D/acc2=0.881801 D/sec= 16.891350 lr=0.999966 eta=0.000019
2019-08-16 03:30:09,846 - main - INFO - [ 33] T/loss=0.000006 T/acc1=1.000000 T/acc2=0.000000 T/sec= 332.021515 D/loss=1.271749 D/acc1=0.881801 D/acc2=0.881801 D/sec= 16.864703 lr=0.999975 eta=0.000018
I0816 03:30:09.846906 139794510784384 <ipython-input-7-90da46432566>:373] [ 33] T/loss=0.000006 T/acc1=1.000000 T/acc2=0.000000 T/sec= 332.021515 D/loss=1.271749 D/acc1=0.881801 D/acc2=0.881801 D/sec= 16.864703 lr=0.999975 eta=0.000018
2019-08-16 03:35:59,271 - main - INFO - [ 34] T/loss=0.002984 T/acc1=0.999271 T/acc2=0.000000 T/sec= 332.553117 D/loss=1.243163 D/acc1=0.877111 D/acc2=0.877111 D/sec= 16.871248 lr=0.999982 eta=0.000017
I0816 03:35:59.271255 139794510784384 <ipython-input-7-90da46432566>:373] [ 34] T/loss=0.002984 T/acc1=0.999271 T/acc2=0.000000 T/sec= 332.553117 D/loss=1.243163 D/acc1=0.877111 D/acc2=0.877111 D/sec= 16.871248 lr=0.999982 eta=0.000017
2019-08-16 03:41:48,854 - main - INFO - [ 35] T/loss=0.001378 T/acc1=0.999792 T/acc2=0.000000 T/sec= 332.688802 D/loss=1.274861 D/acc1=0.875235 D/acc2=0.875235 D/sec= 16.893976 lr=0.999986 eta=0.000016
I0816 03:41:48.854021 139794510784384 <ipython-input-7-90da46432566>:373] [ 35] T/loss=0.001378 T/acc1=0.999792 T/acc2=0.000000 T/sec= 332.688802 D/loss=1.274861 D/acc1=0.875235 D/acc2=0.875235 D/sec= 16.893976 lr=0.999986 eta=0.000016
2019-08-16 03:47:37,759 - main - INFO - [ 36] T/loss=0.003836 T/acc1=0.999375 T/acc2=0.000000 T/sec= 332.008724 D/loss=1.116530 D/acc1=0.879925 D/acc2=0.879925 D/sec= 16.896665 lr=0.999990 eta=0.000015
I0816 03:47:37.759410 139794510784384 <ipython-input-7-90da46432566>:373] [ 36] T/loss=0.003836 T/acc1=0.999375 T/acc2=0.000000 T/sec= 332.008724 D/loss=1.116530 D/acc1=0.879925 D/acc2=0.879925 D/sec= 16.896665 lr=0.999990 eta=0.000015
2019-08-16 03:53:25,992 - main - INFO - [ 37] T/loss=0.001583 T/acc1=0.999687 T/acc2=0.000000 T/sec= 331.336941 D/loss=1.172298 D/acc1=0.879925 D/acc2=0.879925 D/sec= 16.895689 lr=0.999992 eta=0.000014
I0816 03:53:25.992095 139794510784384 <ipython-input-7-90da46432566>:373] [ 37] T/loss=0.001583 T/acc1=0.999687 T/acc2=0.000000 T/sec= 331.336941 D/loss=1.172298 D/acc1=0.879925 D/acc2=0.879925 D/sec= 16.895689 lr=0.999992 eta=0.000014
2019-08-16 03:59:13,043 - main - INFO - [ 38] T/loss=0.001015 T/acc1=0.999896 T/acc2=0.000000 T/sec= 330.158723 D/loss=1.165017 D/acc1=0.878987 D/acc2=0.878987 D/sec= 16.892325 lr=0.999994 eta=0.000013
I0816 03:59:13.043110 139794510784384 <ipython-input-7-90da46432566>:373] [ 38] T/loss=0.001015 T/acc1=0.999896 T/acc2=0.000000 T/sec= 330.158723 D/loss=1.165017 D/acc1=0.878987 D/acc2=0.878987 D/sec= 16.892325 lr=0.999994 eta=0.000013
2019-08-16 04:05:02,720 - main - INFO - [ 39] T/loss=0.002072 T/acc1=0.999583 T/acc2=0.000000 T/sec= 332.763786 D/loss=1.260288 D/acc1=0.872420 D/acc2=0.872420 D/sec= 16.913414 lr=0.999996 eta=0.000012
I0816 04:05:02.720292 139794510784384 <ipython-input-7-90da46432566>:373] [ 39] T/loss=0.002072 T/acc1=0.999583 T/acc2=0.000000 T/sec= 332.763786 D/loss=1.260288 D/acc1=0.872420 D/acc2=0.872420 D/sec= 16.913414 lr=0.999996 eta=0.000012
2019-08-16 04:10:52,892 - main - INFO - [ 40] T/loss=0.001102 T/acc1=0.999687 T/acc2=0.000000 T/sec= 333.291062 D/loss=1.266232 D/acc1=0.874296 D/acc2=0.874296 D/sec= 16.881404 lr=0.999997 eta=0.000011
I0816 04:10:52.892855 139794510784384 <ipython-input-7-90da46432566>:373] [ 40] T/loss=0.001102 T/acc1=0.999687 T/acc2=0.000000 T/sec= 333.291062 D/loss=1.266232 D/acc1=0.874296 D/acc2=0.874296 D/sec= 16.881404 lr=0.999997 eta=0.000011
2019-08-16 04:16:43,116 - main - INFO - [ 41] T/loss=0.000900 T/acc1=0.999896 T/acc2=0.000000 T/sec= 333.282529 D/loss=1.180577 D/acc1=0.878049 D/acc2=0.878049 D/sec= 16.941478 lr=0.999998 eta=0.000010
I0816 04:16:43.116769 139794510784384 <ipython-input-7-90da46432566>:373] [ 41] T/loss=0.000900 T/acc1=0.999896 T/acc2=0.000000 T/sec= 333.282529 D/loss=1.180577 D/acc1=0.878049 D/acc2=0.878049 D/sec= 16.941478 lr=0.999998 eta=0.000010
2019-08-16 04:22:34,589 - main - INFO - [ 42] T/loss=0.000678 T/acc1=0.999896 T/acc2=0.000000 T/sec= 334.531811 D/loss=1.207732 D/acc1=0.874296 D/acc2=0.874296 D/sec= 16.941354 lr=0.999998 eta=0.000009
I0816 04:22:34.589947 139794510784384 <ipython-input-7-90da46432566>:373] [ 42] T/loss=0.000678 T/acc1=0.999896 T/acc2=0.000000 T/sec= 334.531811 D/loss=1.207732 D/acc1=0.874296 D/acc2=0.874296 D/sec= 16.941354 lr=0.999998 eta=0.000009
2019-08-16 04:28:24,822 - main - INFO - [ 43] T/loss=0.000004 T/acc1=1.000000 T/acc2=0.000000 T/sec= 333.314352 D/loss=1.243568 D/acc1=0.876173 D/acc2=0.876173 D/sec= 16.918516 lr=0.999999 eta=0.000008
I0816 04:28:24.822805 139794510784384 <ipython-input-7-90da46432566>:373] [ 43] T/loss=0.000004 T/acc1=1.000000 T/acc2=0.000000 T/sec= 333.314352 D/loss=1.243568 D/acc1=0.876173 D/acc2=0.876173 D/sec= 16.918516 lr=0.999999 eta=0.000008
2019-08-16 04:34:13,836 - main - INFO - [ 44] T/loss=0.000678 T/acc1=0.999896 T/acc2=0.000000 T/sec= 332.110158 D/loss=1.251998 D/acc1=0.876173 D/acc2=0.876173 D/sec= 16.903502 lr=0.999999 eta=0.000007
I0816 04:34:13.836458 139794510784384 <ipython-input-7-90da46432566>:373] [ 44] T/loss=0.000678 T/acc1=0.999896 T/acc2=0.000000 T/sec= 332.110158 D/loss=1.251998 D/acc1=0.876173 D/acc2=0.876173 D/sec= 16.903502 lr=0.999999 eta=0.000007
2019-08-16 04:40:02,270 - main - INFO - [ 45] T/loss=0.000005 T/acc1=1.000000 T/acc2=0.000000 T/sec= 331.532584 D/loss=1.288725 D/acc1=0.872420 D/acc2=0.872420 D/sec= 16.901112 lr=0.999999 eta=0.000006
I0816 04:40:02.270153 139794510784384 <ipython-input-7-90da46432566>:373] [ 45] T/loss=0.000005 T/acc1=1.000000 T/acc2=0.000000 T/sec= 331.532584 D/loss=1.288725 D/acc1=0.872420 D/acc2=0.872420 D/sec= 16.901112 lr=0.999999 eta=0.000006
2019-08-16 04:45:51,651 - main - INFO - [ 46] T/loss=0.000002 T/acc1=1.000000 T/acc2=0.000000 T/sec= 332.479333 D/loss=1.302837 D/acc1=0.873358 D/acc2=0.873358 D/sec= 16.902003 lr=0.999999 eta=0.000005
I0816 04:45:51.651521 139794510784384 <ipython-input-7-90da46432566>:373] [ 46] T/loss=0.000002 T/acc1=1.000000 T/acc2=0.000000 T/sec= 332.479333 D/loss=1.302837 D/acc1=0.873358 D/acc2=0.873358 D/sec= 16.902003 lr=0.999999 eta=0.000005
2019-08-16 04:51:43,034 - main - INFO - [ 47] T/loss=0.000002 T/acc1=1.000000 T/acc2=0.000000 T/sec= 334.474833 D/loss=1.318796 D/acc1=0.872420 D/acc2=0.872420 D/sec= 16.908131 lr=1.000000 eta=0.000004
I0816 04:51:43.034452 139794510784384 <ipython-input-7-90da46432566>:373] [ 47] T/loss=0.000002 T/acc1=1.000000 T/acc2=0.000000 T/sec= 334.474833 D/loss=1.318796 D/acc1=0.872420 D/acc2=0.872420 D/sec= 16.908131 lr=1.000000 eta=0.000004
2019-08-16 04:57:33,795 - main - INFO - [ 48] T/loss=0.000020 T/acc1=1.000000 T/acc2=0.000000 T/sec= 333.847173 D/loss=1.294794 D/acc1=0.878049 D/acc2=0.878049 D/sec= 16.913860 lr=1.000000 eta=0.000003
I0816 04:57:33.795494 139794510784384 <ipython-input-7-90da46432566>:373] [ 48] T/loss=0.000020 T/acc1=1.000000 T/acc2=0.000000 T/sec= 333.847173 D/loss=1.294794 D/acc1=0.878049 D/acc2=0.878049 D/sec= 16.913860 lr=1.000000 eta=0.000003
2019-08-16 05:03:23,233 - main - INFO - [ 49] T/loss=0.000002 T/acc1=1.000000 T/acc2=0.000000 T/sec= 332.489218 D/loss=1.305284 D/acc1=0.873358 D/acc2=0.873358 D/sec= 16.949008 lr=1.000000 eta=0.000002
I0816 05:03:23.233719 139794510784384 <ipython-input-7-90da46432566>:373] [ 49] T/loss=0.000002 T/acc1=1.000000 T/acc2=0.000000 T/sec= 332.489218 D/loss=1.305284 D/acc1=0.873358 D/acc2=0.873358 D/sec= 16.949008 lr=1.000000 eta=0.000002
2019-08-16 05:09:12,896 - main - INFO - [ 50] T/loss=0.000548 T/acc1=0.999896 T/acc2=0.000000 T/sec= 332.742293 D/loss=1.314032 D/acc1=0.868668 D/acc2=0.868668 D/sec= 16.919984 lr=1.000000 eta=0.000001
I0816 05:09:12.896229 139794510784384 <ipython-input-7-90da46432566>:373] [ 50] T/loss=0.000548 T/acc1=0.999896 T/acc2=0.000000 T/sec= 332.742293 D/loss=1.314032 D/acc1=0.868668 D/acc2=0.868668 D/sec= 16.919984 lr=1.000000 eta=0.000001

==== Confusion matrix 1 (early_stopped-loss) ====

	0	1
0	488	45
1	90	443

==== Confusion matrix 2 (early_stopped-loss) ====

	0	1
0	0.92	0.08
1	0.17	0.83

UAR = 0.873358

==== Classification report (early_stopped-loss) ====

              precision    recall  f1-score   support

           0       0.84      0.92      0.88       533
           1       0.91      0.83      0.87       533

    accuracy                           0.87      1066
   macro avg       0.88      0.87      0.87      1066
weighted avg       0.88      0.87      0.87      1066


==== Confusion matrix 1 (early_stopped-uar) ====

	0	1
0	455	78
1	46	487

==== Confusion matrix 2 (early_stopped-uar) ====

	0	1
0	0.85	0.15
1	0.09	0.91

UAR = 0.883677

==== Classification report (early_stopped-uar) ====

              precision    recall  f1-score   support

           0       0.91      0.85      0.88       533
           1       0.86      0.91      0.89       533

    accuracy                           0.88      1066
   macro avg       0.89      0.88      0.88      1066
weighted avg       0.89      0.88      0.88      1066


==== Confusion matrix 1 (final model) ====

	0	1
0	455	78
1	62	471

==== Confusion matrix 2 (final model) ====

	0	1
0	0.85	0.15
1	0.12	0.88

UAR = 0.868668

==== Classification report (final model) ====

              precision    recall  f1-score   support

           0       0.88      0.85      0.87       533
           1       0.86      0.88      0.87       533

    accuracy                           0.87      1066
   macro avg       0.87      0.87      0.87      1066
weighted avg       0.87      0.87      0.87      1066

2019-08-16 05:11:06,770 - <module> - INFO - time spent: 17720.786577 sec

I0816 05:11:06.770507 139794510784384 <ipython-input-7-90da46432566>:648] time spent: 17720.786577 sec
