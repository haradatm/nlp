{
  "gpu": -1,
  "train": "datasets/train.txt",
  "valid": "datasets/test.txt",
  "test": "datasets/test.txt",
  "glove": "datasets/glove.6B.100d.txt",
  "w2v": "",
  "unit": 200,
  "batchsize": 100,
  "epoch": 30,
  "out": "results/result-blstm"
}
2018-09-02 10:26:03,569 - main - INFO - vocabulary size: 24279
2018-09-02 10:26:03,569 - main - INFO - number of word embedding dims: 100
2018-09-02 10:26:03,569 - main - INFO - number of lstm units: 200
2018-09-02 10:26:03,569 - main - INFO - number of tags: 12
2018-09-02 10:26:03,569 - main - INFO - train data length: 14986
2018-09-02 10:26:03,569 - main - INFO - valid data length: 3683
2018-09-02 10:26:03,569 - main - INFO - test  data length: 3683
Initialize word embedding by pre-trained model: datasets/glove.6B.100d.txt
2018-09-02 10:29:52,696 - main - INFO - [  1] T/loss=8.969002 T/f1=0.039367 T/acc=0.813577 T/sec= 205.683472 V/loss=5.340519 V/f1=0.075995 V/acc=0.817870 V/sec= 22.967965 lr=0.015000
saving early stopped-model at epoch 1
2018-09-02 10:34:08,602 - main - INFO - [  2] T/loss=5.527037 T/f1=0.350735 T/acc=0.875364 T/sec= 233.698256 V/loss=3.538035 V/f1=0.440213 V/acc=0.876540 V/sec= 22.207680 lr=0.014925
saving early stopped-model at epoch 2
2018-09-02 10:38:17,430 - main - INFO - [  3] T/loss=4.736679 T/f1=0.564866 T/acc=0.914430 T/sec= 226.017316 V/loss=2.903461 V/f1=0.554737 V/acc=0.901268 V/sec= 22.810787 lr=0.014850
saving early stopped-model at epoch 3
2018-09-02 10:42:33,066 - main - INFO - [  4] T/loss=4.401222 T/f1=0.643158 T/acc=0.928552 T/sec= 233.341144 V/loss=2.569036 V/f1=0.612273 V/acc=0.916667 V/sec= 22.294785 lr=0.014776
saving early stopped-model at epoch 4
2018-09-02 10:46:43,331 - main - INFO - [  5] T/loss=4.164343 T/f1=0.700436 T/acc=0.938950 T/sec= 227.629807 V/loss=2.436848 V/f1=0.636586 V/acc=0.921611 V/sec= 22.635522 lr=0.014702
saving early stopped-model at epoch 5
2018-09-02 10:50:54,733 - main - INFO - [  6] T/loss=3.935710 T/f1=0.750531 T/acc=0.949164 T/sec= 229.377320 V/loss=2.198491 V/f1=0.667790 V/acc=0.930791 V/sec= 22.024109 lr=0.014629
saving early stopped-model at epoch 6
2018-09-02 10:55:05,057 - main - INFO - [  7] T/loss=3.795789 T/f1=0.779631 T/acc=0.955203 T/sec= 228.320084 V/loss=2.052702 V/f1=0.701257 V/acc=0.937694 V/sec= 22.004482 lr=0.014556
saving early stopped-model at epoch 7
2018-09-02 10:59:18,989 - main - INFO - [  8] T/loss=3.656657 T/f1=0.805087 T/acc=0.960671 T/sec= 232.468211 V/loss=2.119144 V/f1=0.696844 V/acc=0.935735 V/sec= 21.463330 lr=0.014483
saving early stopped-model at epoch 8
2018-09-02 11:03:28,361 - main - INFO - [  9] T/loss=3.536752 T/f1=0.825664 T/acc=0.964947 T/sec= 227.773220 V/loss=2.022373 V/f1=0.713282 V/acc=0.939693 V/sec= 21.598775 lr=0.014410
saving early stopped-model at epoch 9
2018-09-02 11:07:29,568 - main - INFO - [ 10] T/loss=3.445101 T/f1=0.840259 T/acc=0.968231 T/sec= 219.975276 V/loss=2.012765 V/f1=0.719484 V/acc=0.940782 V/sec= 21.231710 lr=0.014338
saving early stopped-model at epoch 10
2018-09-02 11:11:42,385 - main - INFO - [ 11] T/loss=3.406596 T/f1=0.850628 T/acc=0.970399 T/sec= 230.752874 V/loss=1.881224 V/f1=0.739788 V/acc=0.945984 V/sec= 22.064349 lr=0.014267
saving early stopped-model at epoch 11
2018-09-02 11:15:51,666 - main - INFO - [ 12] T/loss=3.303935 T/f1=0.859909 T/acc=0.972560 T/sec= 226.655752 V/loss=1.752192 V/f1=0.749595 V/acc=0.949101 V/sec= 22.625307 lr=0.014195
saving early stopped-model at epoch 12
2018-09-02 11:19:59,525 - main - INFO - [ 13] T/loss=3.275745 T/f1=0.872427 T/acc=0.975257 T/sec= 225.915199 V/loss=1.793967 V/f1=0.754864 V/acc=0.949606 V/sec= 21.943737 lr=0.014124
saving early stopped-model at epoch 13
2018-09-02 11:24:07,291 - main - INFO - [ 14] T/loss=3.185209 T/f1=0.883031 T/acc=0.977225 T/sec= 226.031357 V/loss=1.888573 V/f1=0.746628 V/acc=0.946612 V/sec= 21.734518 lr=0.014054
saving early stopped-model at epoch 14
2018-09-02 11:28:14,212 - main - INFO - [ 15] T/loss=3.189996 T/f1=0.887559 T/acc=0.978276 T/sec= 225.476415 V/loss=1.885301 V/f1=0.748292 V/acc=0.946153 V/sec= 21.444922 lr=0.013983
2018-09-02 12:16:09,497 - main - INFO - [ 16] T/loss=3.100990 T/f1=0.894449 T/acc=0.980217 T/sec= 2854.808936 V/loss=1.828208 V/f1=0.763520 V/acc=0.949445 V/sec= 20.475423 lr=0.013914
saving early stopped-model at epoch 16
2018-09-02 12:20:08,030 - main - INFO - [ 17] T/loss=3.066026 T/f1=0.900226 T/acc=0.981224 T/sec= 217.008026 V/loss=1.737081 V/f1=0.767535 V/acc=0.951279 V/sec= 21.525707 lr=0.013844
saving early stopped-model at epoch 17
2018-09-02 12:24:13,260 - main - INFO - [ 18] T/loss=3.038626 T/f1=0.904450 T/acc=0.982355 T/sec= 223.414792 V/loss=1.819399 V/f1=0.767793 V/acc=0.950487 V/sec= 21.814553 lr=0.013775
saving early stopped-model at epoch 18
2018-09-02 12:28:11,239 - main - INFO - [ 19] T/loss=2.998095 T/f1=0.909838 T/acc=0.983143 T/sec= 217.470644 V/loss=1.761093 V/f1=0.774489 V/acc=0.952512 V/sec= 20.508224 lr=0.013706
saving early stopped-model at epoch 19
2018-09-02 12:32:07,012 - main - INFO - [ 20] T/loss=3.001778 T/f1=0.911734 T/acc=0.983588 T/sec= 214.940192 V/loss=1.771760 V/f1=0.768090 V/acc=0.950602 V/sec= 20.833043 lr=0.013637
2018-09-02 12:36:01,009 - main - INFO - [ 21] T/loss=2.937623 T/f1=0.911789 T/acc=0.984034 T/sec= 213.201874 V/loss=1.676964 V/f1=0.776441 V/acc=0.954160 V/sec= 20.795223 lr=0.013569
saving early stopped-model at epoch 21
/Users/haradatm/.pyenv/versions/miniconda3-latest/envs/py3/lib/python3.6/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2018-09-02 12:39:55,462 - main - INFO - [ 22] T/loss=2.947583 T/f1=0.920241 T/acc=0.985476 T/sec= 214.074797 V/loss=1.789144 V/f1=0.773150 V/acc=0.951984 V/sec= 20.377949 lr=0.013501
2018-09-02 12:43:48,564 - main - INFO - [ 23] T/loss=2.912617 T/f1=0.922239 T/acc=0.986007 T/sec= 212.336791 V/loss=1.681179 V/f1=0.783183 V/acc=0.954495 V/sec= 20.765706 lr=0.013434
saving early stopped-model at epoch 23
2018-09-02 12:47:47,670 - main - INFO - [ 24] T/loss=2.907679 T/f1=0.923668 T/acc=0.986196 T/sec= 217.763035 V/loss=1.636067 V/f1=0.782315 V/acc=0.954524 V/sec= 21.342600 lr=0.013367
saving early stopped-model at epoch 24
2018-09-02 12:51:47,743 - main - INFO - [ 25] T/loss=2.842546 T/f1=0.926298 T/acc=0.986587 T/sec= 218.966809 V/loss=1.768672 V/f1=0.784271 V/acc=0.954124 V/sec= 21.106590 lr=0.013300
saving early stopped-model at epoch 25
2018-09-02 12:55:46,986 - main - INFO - [ 26] T/loss=2.829516 T/f1=0.931462 T/acc=0.988244 T/sec= 218.168055 V/loss=1.781184 V/f1=0.779526 V/acc=0.952992 V/sec= 21.075076 lr=0.013233
saving early stopped-model at epoch 26
2018-09-02 12:59:47,314 - main - INFO - [ 27] T/loss=2.812936 T/f1=0.935744 T/acc=0.988954 T/sec= 219.342239 V/loss=1.766929 V/f1=0.782393 V/acc=0.953616 V/sec= 20.984985 lr=0.013167
saving early stopped-model at epoch 27
2018-09-02 13:03:44,891 - main - INFO - [ 28] T/loss=2.791097 T/f1=0.935852 T/acc=0.989005 T/sec= 216.994033 V/loss=1.718614 V/f1=0.780832 V/acc=0.953984 V/sec= 20.583633 lr=0.013101
saving early stopped-model at epoch 28
2018-09-02 13:07:42,908 - main - INFO - [ 29] T/loss=2.754748 T/f1=0.940333 T/acc=0.989735 T/sec= 217.241075 V/loss=1.760537 V/f1=0.785450 V/acc=0.954941 V/sec= 20.775886 lr=0.013036
saving early stopped-model at epoch 29
2018-09-02 13:11:34,859 - main - INFO - [ 30] T/loss=2.731622 T/f1=0.942859 T/acc=0.990203 T/sec= 212.041916 V/loss=1.727283 V/f1=0.787506 V/acc=0.955804 V/sec= 19.909130 lr=0.012971
saving early stopped-model at epoch 30
loading early stopped-model at epoch 30
             precision    recall  f1-score   support

        PER       0.90      0.79      0.84      1617
       MISC       0.80      0.62      0.70       702
        ORG       0.85      0.63      0.72      1661
        LOC       0.86      0.86      0.86      1668

avg / total       0.86      0.74      0.80      5648

2018-09-02 13:11:41,206 - <module> - INFO - time spent: 10001.290546 sec

