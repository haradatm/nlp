{
  "gpu": -1,
  "train": "datasets/train.txt",
  "valid": "datasets/test.txt",
  "test": "datasets/test.txt",
  "glove": "datasets/glove.6B.100d.txt",
  "w2v": "",
  "unit": 200,
  "batchsize": 100,
  "epoch": 30,
  "out": "results/result-blstm-cnn"
}
2018-09-02 10:26:49,397 - main - INFO - vocabulary size: 24279
2018-09-02 10:26:49,397 - main - INFO - number of word embedding dims: 100
2018-09-02 10:26:49,397 - main - INFO - number of lstm units: 200
2018-09-02 10:26:49,398 - main - INFO - number of tags: 12
2018-09-02 10:26:49,398 - main - INFO - train data length: 14986
2018-09-02 10:26:49,398 - main - INFO - valid data length: 3683
2018-09-02 10:26:49,398 - main - INFO - test  data length: 3683
Initialize word embedding by pre-trained model: datasets/glove.6B.100d.txt
2018-09-02 10:35:19,566 - main - INFO - [  1] T/loss=9.885661 T/f1=0.010051 T/acc=0.794756 T/sec= 452.820981 V/loss=5.874088 V/f1=0.019874 V/acc=0.808041 V/sec= 56.707849 lr=0.015000
saving early stopped-model at epoch 1
2018-09-02 10:43:49,853 - main - INFO - [  2] T/loss=5.728540 T/f1=0.284735 T/acc=0.863630 T/sec= 454.365837 V/loss=3.695894 V/f1=0.405687 V/acc=0.868436 V/sec= 55.920970 lr=0.014925
saving early stopped-model at epoch 2
2018-09-02 10:52:18,862 - main - INFO - [  3] T/loss=4.811213 T/f1=0.558696 T/acc=0.912420 T/sec= 451.955203 V/loss=2.760527 V/f1=0.576918 V/acc=0.903940 V/sec= 57.054142 lr=0.014850
saving early stopped-model at epoch 3
2018-09-02 11:00:47,429 - main - INFO - [  4] T/loss=4.399551 T/f1=0.651975 T/acc=0.930188 T/sec= 452.455868 V/loss=2.290992 V/f1=0.644165 V/acc=0.923967 V/sec= 56.111003 lr=0.014776
saving early stopped-model at epoch 4
2018-09-02 11:09:02,883 - main - INFO - [  5] T/loss=4.122870 T/f1=0.719984 T/acc=0.942816 T/sec= 439.177732 V/loss=2.135533 V/f1=0.671611 V/acc=0.931003 V/sec= 56.276038 lr=0.014702
saving early stopped-model at epoch 5
2018-09-02 11:17:27,838 - main - INFO - [  6] T/loss=3.894106 T/f1=0.766453 T/acc=0.952035 T/sec= 450.736840 V/loss=2.006438 V/f1=0.695937 V/acc=0.936675 V/sec= 54.217764 lr=0.014629
saving early stopped-model at epoch 6
2018-09-02 11:25:49,236 - main - INFO - [  7] T/loss=3.766624 T/f1=0.791833 T/acc=0.957916 T/sec= 446.652199 V/loss=1.841553 V/f1=0.725599 V/acc=0.944277 V/sec= 54.746319 lr=0.014556
saving early stopped-model at epoch 7
2018-09-02 12:18:01,296 - main - INFO - [  8] T/loss=3.617043 T/f1=0.816193 T/acc=0.962451 T/sec= 3079.550329 V/loss=1.798598 V/f1=0.739953 V/acc=0.946553 V/sec= 52.509651 lr=0.014483
saving early stopped-model at epoch 8
2018-09-02 12:26:11,333 - main - INFO - [  9] T/loss=3.507104 T/f1=0.833710 T/acc=0.966628 T/sec= 436.693011 V/loss=1.759407 V/f1=0.751306 V/acc=0.949086 V/sec= 53.343509 lr=0.014410
saving early stopped-model at epoch 9
2018-09-02 12:34:03,566 - main - INFO - [ 10] T/loss=3.428653 T/f1=0.846266 T/acc=0.969423 T/sec= 420.075418 V/loss=1.777999 V/f1=0.754183 V/acc=0.949395 V/sec= 52.158182 lr=0.014338
saving early stopped-model at epoch 10
2018-09-02 12:41:54,041 - main - INFO - [ 11] T/loss=3.316493 T/f1=0.857095 T/acc=0.971879 T/sec= 418.604036 V/loss=1.703420 V/f1=0.762498 V/acc=0.951805 V/sec= 51.870369 lr=0.014267
saving early stopped-model at epoch 11
2018-09-02 12:49:52,289 - main - INFO - [ 12] T/loss=3.313300 T/f1=0.869847 T/acc=0.974488 T/sec= 424.988143 V/loss=1.655251 V/f1=0.767738 V/acc=0.952313 V/sec= 53.260301 lr=0.014195
saving early stopped-model at epoch 12
2018-09-02 12:57:54,193 - main - INFO - [ 13] T/loss=3.247734 T/f1=0.878218 T/acc=0.976375 T/sec= 428.831986 V/loss=1.671365 V/f1=0.769802 V/acc=0.952992 V/sec= 53.071354 lr=0.014124
saving early stopped-model at epoch 13
2018-09-02 13:05:51,956 - main - INFO - [ 14] T/loss=3.208566 T/f1=0.882605 T/acc=0.977468 T/sec= 424.678537 V/loss=1.688111 V/f1=0.771488 V/acc=0.952155 V/sec= 53.085072 lr=0.014054
saving early stopped-model at epoch 14
2018-09-02 13:13:04,680 - main - INFO - [ 15] T/loss=3.130081 T/f1=0.888666 T/acc=0.978513 T/sec= 397.058414 V/loss=1.535991 V/f1=0.781821 V/acc=0.955220 V/sec= 35.665040 lr=0.013983
saving early stopped-model at epoch 15
2018-09-02 13:18:28,373 - main - INFO - [ 16] T/loss=3.097393 T/f1=0.896609 T/acc=0.980281 T/sec= 288.604093 V/loss=1.555196 V/f1=0.783849 V/acc=0.955477 V/sec= 35.089406 lr=0.013914
saving early stopped-model at epoch 16
2018-09-02 13:23:56,419 - main - INFO - [ 17] T/loss=3.060121 T/f1=0.903596 T/acc=0.981619 T/sec= 291.883502 V/loss=1.566428 V/f1=0.788267 V/acc=0.955572 V/sec= 36.162325 lr=0.013844
saving early stopped-model at epoch 17
2018-09-02 13:29:32,585 - main - INFO - [ 18] T/loss=2.999396 T/f1=0.905696 T/acc=0.982285 T/sec= 296.666526 V/loss=1.579027 V/f1=0.785287 V/acc=0.954950 V/sec= 39.499951 lr=0.013775
saving early stopped-model at epoch 18
2018-09-02 13:35:10,307 - main - INFO - [ 19] T/loss=2.998578 T/f1=0.906850 T/acc=0.982642 T/sec= 301.233391 V/loss=1.600059 V/f1=0.788795 V/acc=0.955459 V/sec= 36.487953 lr=0.013706
saving early stopped-model at epoch 19
2018-09-02 13:40:46,348 - main - INFO - [ 20] T/loss=2.915398 T/f1=0.914412 T/acc=0.984182 T/sec= 299.438132 V/loss=1.518245 V/f1=0.798094 V/acc=0.958474 V/sec= 36.602939 lr=0.013637
saving early stopped-model at epoch 20
2018-09-02 13:46:19,254 - main - INFO - [ 21] T/loss=2.925045 T/f1=0.918251 T/acc=0.985046 T/sec= 296.127457 V/loss=1.635910 V/f1=0.793230 V/acc=0.956316 V/sec= 36.778483 lr=0.013569
/Users/haradatm/.pyenv/versions/miniconda3-latest/envs/py3/lib/python3.6/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2018-09-02 13:51:55,059 - main - INFO - [ 22] T/loss=2.920487 T/f1=0.919281 T/acc=0.985037 T/sec= 299.242362 V/loss=1.494498 V/f1=0.798486 V/acc=0.958289 V/sec= 36.563371 lr=0.013501
2018-09-02 13:57:31,767 - main - INFO - [ 23] T/loss=2.888228 T/f1=0.922911 T/acc=0.986021 T/sec= 299.209121 V/loss=1.674399 V/f1=0.786091 V/acc=0.954862 V/sec= 37.498238 lr=0.013434
saving early stopped-model at epoch 23
2018-09-02 14:03:12,754 - main - INFO - [ 24] T/loss=2.845244 T/f1=0.925856 T/acc=0.986691 T/sec= 303.218596 V/loss=1.495154 V/f1=0.799644 V/acc=0.958502 V/sec= 37.768439 lr=0.013367
saving early stopped-model at epoch 24
2018-09-02 14:08:51,652 - main - INFO - [ 25] T/loss=2.823272 T/f1=0.928037 T/acc=0.987381 T/sec= 302.055826 V/loss=1.594219 V/f1=0.799031 V/acc=0.958541 V/sec= 36.842460 lr=0.013300
saving early stopped-model at epoch 25
2018-09-02 14:14:29,385 - main - INFO - [ 26] T/loss=2.812158 T/f1=0.930795 T/acc=0.987958 T/sec= 300.075648 V/loss=1.699039 V/f1=0.793744 V/acc=0.956171 V/sec= 37.656841 lr=0.013233
saving early stopped-model at epoch 26
2018-09-02 14:20:03,663 - main - INFO - [ 27] T/loss=2.789525 T/f1=0.932664 T/acc=0.988142 T/sec= 297.622843 V/loss=1.584465 V/f1=0.799253 V/acc=0.957992 V/sec= 36.655165 lr=0.013167
saving early stopped-model at epoch 27
2018-09-02 14:25:41,973 - main - INFO - [ 28] T/loss=2.772682 T/f1=0.934243 T/acc=0.988852 T/sec= 301.620368 V/loss=1.662657 V/f1=0.790784 V/acc=0.955307 V/sec= 36.689588 lr=0.013101
saving early stopped-model at epoch 28
2018-09-02 14:31:34,369 - main - INFO - [ 29] T/loss=2.759045 T/f1=0.934549 T/acc=0.989095 T/sec= 314.770489 V/loss=1.805328 V/f1=0.792603 V/acc=0.955538 V/sec= 37.626158 lr=0.013036
saving early stopped-model at epoch 29
2018-09-02 14:37:26,988 - main - INFO - [ 30] T/loss=2.731813 T/f1=0.935636 T/acc=0.989029 T/sec= 314.137261 V/loss=1.621911 V/f1=0.797104 V/acc=0.957198 V/sec= 38.481923 lr=0.012971
saving early stopped-model at epoch 30
loading early stopped-model at epoch 30
             precision    recall  f1-score   support

        PER       0.93      0.82      0.87      1617
        ORG       0.86      0.63      0.73      1661
       MISC       0.80      0.60      0.68       702
        LOC       0.87      0.87      0.87      1668

avg / total       0.87      0.75      0.81      5648

2018-09-02 14:37:45,574 - <module> - INFO - time spent: 15131.272154 sec

